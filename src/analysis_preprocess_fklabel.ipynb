{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_DIR = 'train_first'\n",
    "\n",
    "CCBA_PATH = 'train_first/public_train_x_ccba_full_hashed.csv'\n",
    "CDTX_PATH = 'train_first/public_train_x_cdtx0001_full_hashed.csv'\n",
    "CUSTINFO_PATH = 'train_first/public_train_x_custinfo_full_hashed.csv'\n",
    "DP_PATH = 'train_first/public_train_x_dp_full_hashed.csv'\n",
    "REMIT_PATH = 'train_first/public_train_x_remit_full_hashed.csv'\n",
    "PDATE_PATH = 'train_first/public_x_alert_date.csv'\n",
    "TDATE_PATH = 'train_first/train_x_alert_date.csv'\n",
    "\n",
    "# the released answer \n",
    "\n",
    "ANSWER_PATH = 'train_first/train_y_answer.csv'\n",
    "SAMPLE_PATH = './sample_submission.csv'\n",
    "\n",
    "\n",
    "ccba = pd.read_csv(CCBA_PATH)\n",
    "cdtx = pd.read_csv(CDTX_PATH)\n",
    "cinfo = pd.read_csv(CUSTINFO_PATH)\n",
    "dp = pd.read_csv(DP_PATH)\n",
    "remit = pd.read_csv(REMIT_PATH)\n",
    "pdate = pd.read_csv(PDATE_PATH)\n",
    "\n",
    "tdate = pd.read_csv(TDATE_PATH)\n",
    "answer = pd.read_csv(ANSWER_PATH)\n",
    "sample = pd.read_csv(SAMPLE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ccba', 'cdtx', 'custinfo', 'dp', 'remit', 'pdate', 'tdate', 'answer', 'sample']\n",
    "datas = [ccba, cdtx, cinfo, dp, remit, pdate, tdate, answer, sample]\n",
    "num_files = len(datas)\n",
    "\n",
    "# for i in range(num_files):\n",
    "#     print(f'{names[i]}: {datas[i].shape}')\n",
    "#     profile = ProfileReport(datas[i], minimal=True, title=names[i])\n",
    "#     profile.to_file(f'./data_report/{names[i]}.html', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from process_data.data_config import (DataSource, FeatureType,\n",
    "                         CCBAConfig, CDTXConfig, DPConfig, REMITConfig, CUSTINFOConfig,\n",
    "                         CONFIG_MAP)\n",
    "from process_data.utils import load_yaml, save_yaml, save_pickle, load_pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Date and target to `custinfo`\n",
    "### 12/22 Let labels be associated with `cust_id` and dates within +- 30 days instead of `alert_key`\n",
    "a sar_flag = 1's transaction label is diffused to the alert_keys of the same cust_id within +- 30 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.concat([pdate, tdate], axis=0)\n",
    "cinfo = cinfo.merge(date, on='alert_key', how='left')\n",
    "cinfo = cinfo.merge(answer, on='alert_key', how='left')\n",
    "cinfo\n",
    "x = cinfo[cinfo['sar_flag'] == 1]\n",
    "sar_custs = x['cust_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "days = 30 \n",
    "expanded_sars = []\n",
    "gc = cinfo.groupby('cust_id')\n",
    "custs = gc.groups.keys()\n",
    "for cust in custs:\n",
    "    cust_alerts = gc.get_group(cust) \n",
    "    cust_alerts = cust_alerts.sort_values(by='date')\n",
    "    alert_time = cust_alerts[cust_alerts.sar_flag == 1]['date'] \n",
    "    alert_span = [] \n",
    "    for i in range(len(alert_time)):\n",
    "        t = alert_time.iloc[i]\n",
    "        alert_span.append((t - days, \n",
    "                        t + days)) \n",
    "    for _, ca in cust_alerts.iterrows():\n",
    "        for span in alert_span:\n",
    "            if ca['date'] > span[0] and ca['date'] < span[1]:\n",
    "                expanded_sars.append(ca['alert_key']) \n",
    "                break \n",
    "\n",
    "fake_cinfo = cinfo.copy()\n",
    "fake_cinfo['sar_flag_fake'] = fake_cinfo['alert_key'].apply(lambda x: 1 if x in expanded_sars else 0)\n",
    "fake_cinfo['sar_flag_fake'].value_counts(dropna = False)\n",
    "fake_cinfo.drop(columns=['sar_flag'], inplace=True)\n",
    "fake_cinfo.rename(columns={'sar_flag_fake': 'sar_flag'}, inplace=True)\n",
    "cinfo = fake_cinfo.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25218\n",
       "1      533\n",
       "Name: sar_flag, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cinfo['sar_flag'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alert_key</th>\n",
       "      <th>cust_id</th>\n",
       "      <th>risk_rank</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>total_asset</th>\n",
       "      <th>AGE</th>\n",
       "      <th>date</th>\n",
       "      <th>sar_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352249</td>\n",
       "      <td>82595ac69158ae08d34156784bdec0d9e2ca5b242b6d2a...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1465816.0</td>\n",
       "      <td>7</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352253</td>\n",
       "      <td>b212d14cb35676926682b2cf849e295d948888f556c07e...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98177.0</td>\n",
       "      <td>2</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352254</td>\n",
       "      <td>e5b0002791c7852644a2730abeaa893cdf14a072ef7812...</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2052922.0</td>\n",
       "      <td>7</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>352280</td>\n",
       "      <td>74214c478dc6519fbefe4bc31693865bdcd698ab974b64...</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>201906.0</td>\n",
       "      <td>5</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>352282</td>\n",
       "      <td>0340e7611f0d82c3cb87e6194fa14bb2ccf8afbf1b3418...</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7450.0</td>\n",
       "      <td>5</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alert_key                                            cust_id  risk_rank  \\\n",
       "0     352249  82595ac69158ae08d34156784bdec0d9e2ca5b242b6d2a...          1   \n",
       "1     352253  b212d14cb35676926682b2cf849e295d948888f556c07e...          1   \n",
       "2     352254  e5b0002791c7852644a2730abeaa893cdf14a072ef7812...          1   \n",
       "3     352280  74214c478dc6519fbefe4bc31693865bdcd698ab974b64...          3   \n",
       "4     352282  0340e7611f0d82c3cb87e6194fa14bb2ccf8afbf1b3418...          1   \n",
       "\n",
       "   occupation_code  total_asset  AGE  date  sar_flag  \n",
       "0             19.0    1465816.0    7   365         0  \n",
       "1              2.0      98177.0    2   365         0  \n",
       "2             19.0    2052922.0    7   365         0  \n",
       "3             15.0     201906.0    5   365         0  \n",
       "4             12.0       7450.0    5   365         0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = cinfo[~cinfo.sar_flag.isna()]\n",
    "traindata.cust_id.nunique()\n",
    "traindata = traindata.drop_duplicates(subset=['cust_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Numerical and Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(col):\n",
    "    qt = QuantileTransformer(\n",
    "        n_quantiles=10_000, \n",
    "        random_state=0, \n",
    "        subsample=min(5*10**5, len(col)),\n",
    "        output_distribution='normal'\n",
    "    )\n",
    "    return qt.fit_transform(col)\n",
    "\n",
    "def process_numerical(col):\n",
    "    col = normalize(col)\n",
    "    col = np.nan_to_num(col, nan=0)\n",
    "    return col\n",
    "\n",
    "\n",
    "def process_catgorical(col):\n",
    "    col.fillna('NULL', inplace=True)\n",
    "    map_dict = {v:i for i, v in enumerate(set(col.unique()))}\n",
    "    col = col.map(map_dict)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numericals: ['lupay', 'cycam', 'usgam', 'clamt', 'csamt', 'inamt', 'cucsm', 'cucah']\n",
      "process categorical country\n",
      "process categorical cur_type\n",
      "numericals: ['amt']\n",
      "process categorical debit_credit\n",
      "process categorical tx_time\n",
      "process categorical tx_type\n",
      "process categorical info_asset_code\n",
      "process categorical fiscTxId\n",
      "process categorical txbranch\n",
      "process categorical cross_bank\n",
      "process categorical ATM\n",
      "numericals: ['tx_amt', 'exchg_rate']\n",
      "process categorical trans_no\n",
      "numericals: ['trade_amount_usd']\n",
      "process categorical risk_rank\n",
      "process categorical occupation_code\n",
      "process categorical AGE\n",
      "numericals: ['total_asset']\n"
     ]
    }
   ],
   "source": [
    "datas = [\n",
    "    (ccba, DataSource.CCBA), \n",
    "    (cdtx, DataSource.CDTX),\n",
    "    (dp, DataSource.DP),\n",
    "    (remit, DataSource.REMIT),\n",
    "    (cinfo, DataSource.CUSTINFO),\n",
    "]\n",
    "\n",
    "num_cat_dict = {}\n",
    "\n",
    "# process numerical and categorical and data_source\n",
    "for data, data_source in datas:\n",
    "    config = CONFIG_MAP[data_source]\n",
    "    cols = data.columns\n",
    "    numericals = []\n",
    "    for col in cols:\n",
    "        feature_type = getattr(config, col)\n",
    "        if feature_type == FeatureType.NUMERICAL and col != 'sar_flag':\n",
    "            numericals.append(col)\n",
    "        elif feature_type == FeatureType.CATEGORICAL: # sar_flag 應該設定在 TARGET type\n",
    "            print(f'process categorical {col}')\n",
    "            data[col] = process_catgorical(data[col].copy())\n",
    "            num_cat = data[col].nunique()\n",
    "            if data_source not in num_cat_dict:\n",
    "                num_cat_dict[data_source] = {}\n",
    "            num_cat_dict[data_source][col] = num_cat\n",
    "    print(f'numericals: {numericals}')\n",
    "    if numericals:\n",
    "        data[numericals] = process_numerical(data[numericals].copy())\n",
    "    data['data_source'] = data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_yaml(num_cat_dict, 'num_cat_dict_fake.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = [d[0] for d in datas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_g = [d.groupby(by='cust_id') for d in datas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7708/7708 [00:52<00:00, 145.68it/s] \n"
     ]
    }
   ],
   "source": [
    "def get_date(d):\n",
    "    ds = d.data_source\n",
    "    \n",
    "    if ds == DataSource.CCBA:\n",
    "        date = d.byymm\n",
    "    elif ds == DataSource.CDTX:\n",
    "        date = d.date\n",
    "    elif ds == DataSource.DP:\n",
    "        date = d.tx_date\n",
    "    elif ds == DataSource.REMIT:\n",
    "        date = d.trans_date\n",
    "    elif ds == DataSource.CUSTINFO:\n",
    "        date = d.date\n",
    "    return date, ds\n",
    "\n",
    "\n",
    "cust_ids = cinfo.cust_id.unique()\n",
    "save_data = edict()\n",
    "for cust_id in tqdm(cust_ids):\n",
    "    # get all data from each group\n",
    "    cust_data = []\n",
    "    for d in datas_g:\n",
    "        if not cust_id in d.groups:\n",
    "            continue\n",
    "        cust_data += d.get_group(cust_id).to_dict('records')\n",
    "    for i in range(len(cust_data)):\n",
    "        cust_data[i] = edict(cust_data[i])\n",
    "    \n",
    "    # sort by date\n",
    "    cust_data.sort(key=get_date)\n",
    "    \n",
    "    # generate source list and target_mask\n",
    "    source_list = []\n",
    "    train_mask = []\n",
    "    test_mask = []\n",
    "    for i, c in enumerate(cust_data):\n",
    "        ds = c.data_source\n",
    "        source_list.append(ds)\n",
    "        \n",
    "        if ds != DataSource.CUSTINFO:\n",
    "            pass\n",
    "        # 之後process的 c （table row）都確保是custinfo 確認有sar_flag的存在\n",
    "        else:\n",
    "            \n",
    "            # print(cust_id, c.sar_flag, np.isnan(c.sar_flag))            \n",
    "            if np.isnan(c.sar_flag):\n",
    "                \n",
    "                test_mask.append(i)\n",
    "            else:\n",
    "            \n",
    "                train_mask.append(i)\n",
    "    \n",
    "    # save data\n",
    "    save_data[cust_id] = edict({\n",
    "        'sources': source_list,\n",
    "        'train_mask': train_mask,\n",
    "        'test_mask': test_mask,\n",
    "        'cust_data': cust_data,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check num of train_mask, test_mask is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25218\n",
       "1      533\n",
       "Name: sar_flag, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cinfo.sar_flag.value_counts(dropna=False) # cinfo sar = np.nan （testmask）已經被變成 2 了：）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25751 25751\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "isna = cinfo.sar_flag.isna()\n",
    "train_num = sum(~isna)\n",
    "test_num = sum(isna)\n",
    "\n",
    "train_num2 = 0\n",
    "test_num2 = 0\n",
    "for v in save_data.values():\n",
    "    train_num2 += len(v.train_mask)\n",
    "    test_num2 += len(v.test_mask)\n",
    "\n",
    "print(train_num, train_num2)\n",
    "print(test_num, test_num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(save_data, '/home/nanaeilish/projects/esun_sar_baseline/cust_data_fake.pkl')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking (no save data afterwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "custids = list(save_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrandom\u001b[39;00m \u001b[39mimport\u001b[39;00m choice \n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpprint\u001b[39;00m \u001b[39mimport\u001b[39;00m pprint \n\u001b[0;32m----> 3\u001b[0m custid \u001b[39m=\u001b[39m choice(custids)\n\u001b[1;32m      4\u001b[0m cust_data \u001b[39m=\u001b[39m save_data[custid]\n\u001b[1;32m      5\u001b[0m pprint(cust_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'custids' is not defined"
     ]
    }
   ],
   "source": [
    "from random import choice \n",
    "from pprint import pprint \n",
    "custid = choice(custids)\n",
    "cust_data = save_data[custid]\n",
    "# pprint(cust_data)\n",
    "# if cust_data.train_mask: \n",
    "    # print('train')\n",
    "# elif cust_data.test_mask: \n",
    "    # print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "## testing the data loader code (test.py bug)\n",
    "pkl = save_data \n",
    "data = [] \n",
    "data_count = 0 \n",
    "for k, v in pkl.items():\n",
    "    masks = v.test_mask\n",
    "    for e in masks:\n",
    "        e += 1\n",
    "        s = max(e -512, 0)\n",
    "        data.append(edict({\n",
    "            'sources': v.sources[s:e],\n",
    "            'cust_data': v.cust_data[s:e]\n",
    "        }))\n",
    "        data_count += 1\n",
    "print(f'num of data: {len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# get len of cust_data of save_data\n",
    "lens = []\n",
    "for k, v in save_data.items():\n",
    "    lens.append(len(v.sources))\n",
    "pd.DataFrame(data=lens, columns=None).describe(percentiles=[.25, .5, .75, .9, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check target_mask distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_mask = []\n",
    "test_mask = []\n",
    "for v in save_data.values():\n",
    "    train_mask += v.train_mask\n",
    "    test_mask += v.test_mask\n",
    "\n",
    "display(pd.DataFrame(data=train_mask, columns=['train']).describe(percentiles=np.linspace(0,1,11)))\n",
    "display(pd.DataFrame(data=test_mask, columns=['test']).describe(percentiles=np.linspace(0,1,11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "data = load_pickle('/media/hd03/axot_data/sar/data/cust_data.pkl')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "sars = set()\n",
    "for cust_id, v in data.items():\n",
    "    for idx in v.train_mask:\n",
    "        if v.cust_data[idx].sar_flag == 1:\n",
    "            sars.add(cust_id)\n",
    "            break\n",
    "len(sars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "num1 = []\n",
    "for cust_id in sars:\n",
    "    d = data[cust_id]\n",
    "    tmp = 0\n",
    "    for idx in d.train_mask:\n",
    "        tmp += (d.cust_data[idx].sar_flag == 1)\n",
    "    num1.append(tmp)\n",
    "sum(num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# num_sar = []\n",
    "num_len = []\n",
    "num0 = []\n",
    "num1 = []\n",
    "for k, d in data.items():\n",
    "    tmp0 = 0\n",
    "    tmp1 = 0\n",
    "    for idx in d.train_mask:\n",
    "        tmp0 += d.cust_data[idx].sar_flag == 0\n",
    "        tmp1 += d.cust_data[idx].sar_flag == 1\n",
    "    num0.append(tmp0)\n",
    "    num1.append(tmp1)\n",
    "    num_len.append(len(d.cust_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'num0': num0, 'num1':num1,'num_len': num_len})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "df[df.num1>0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.15 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3.8 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mask_ids = []\n",
    "for k, v in data.items():\n",
    "    for i, idx in enumerate(v.train_mask):\n",
    "        if i == 0:\n",
    "            mask_ids.append(idx)\n",
    "        else:\n",
    "            mask_ids.append(idx-v.train_mask[i-1])\n",
    "pd.DataFrame({'mask_ids': mask_ids}).describe(percentiles=np.arange(.9, 1.01, 0.01))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b1ccb4e24fe2bd647099f34f9af1e095f78eb228d9e967610fb4b32957b1bc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
